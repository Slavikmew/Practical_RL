{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov decision process\n",
    "\n",
    "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
    "\n",
    "State transition is defined by $P(s' |s,a)$ - how likely are you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience.\n",
    "\n",
    "_This notebook is inspired by the awesome_ [CS294](https://github.com/berkeleydeeprlcourse/homework/blob/36a0b58261acde756abd55306fbe63df226bf62b/hw2/HW2.ipynb) _by Berkeley_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's define a simple MDP from this picture:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg\" width=\"400px\" alt=\"Diagram by Waldoalvarez via Wikimedia Commons, CC BY-SA 4.0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you Colab, uncomment this please\n",
    "# !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week02_value_based/mdp.py\n",
    "\n",
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's2': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use MDP just as any other gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = s0\n",
      "next_state = s2, reward = 0.0, done = False\n"
     ]
    }
   ],
   "source": [
    "print('initial state =', mdp.reset())\n",
    "next_state, reward, done, info = mdp.step('a1')\n",
    "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it also has other methods that you'll need for Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.get_all_states = ('s0', 's1', 's2')\n",
      "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
      "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
      "mdp.get_reward('s1', 'a0', 's0') =  5\n",
      "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
    "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \",\n",
    "      mdp.get_transition_prob('s1', 'a0', 's0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Visualizing MDPs\n",
    "\n",
    "You can also visualize any MDP with the drawing fuction donated by [neer201](https://github.com/neer201).\n",
    "\n",
    "You have to install graphviz for system and for python. For ubuntu just run:\n",
    "\n",
    "1. `sudo apt-get install graphviz`\n",
    "2. `pip install graphviz`\n",
    "3. restart the notebook\n",
    "\n",
    "__Note:__ Installing graphviz on some OS (esp. Windows) may be tricky. However, you can ignore this part alltogether and use the standart vizualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_graphviz = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    from mdp import plot_graph, plot_graph_with_state_values, \\\n",
    "        plot_graph_optimal_strategy_and_state_values\n",
    "\n",
    "    display(plot_graph(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
    "\n",
    "Here's the pseudo-code for VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    " \n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to compute the state-action value function $Q^{\\pi}$, defined as follows\n",
    "\n",
    "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mdp_get_action_value.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mdp_get_action_value.py\n",
    "\n",
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
    "    result = 0\n",
    "    for to_state in mdp.get_all_states():\n",
    "        transition_probability = mdp.get_transition_prob(state, action, to_state)\n",
    "        reward = mdp.get_reward(state, action, to_state)\n",
    "        result += transition_probability * (reward + gamma * state_values[to_state])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp_get_action_value import get_action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Vs = {s: i for i, s in enumerate(sorted(mdp.get_all_states()))}\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
    " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\" Computes next V(s) as in formula above. Please do not change state_values in process. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0\n",
    "    result = None\n",
    "    for action in mdp.get_possible_actions(state):\n",
    "        action_value = get_action_value(mdp, state_values, state, action, gamma)\n",
    "        if result == None or result < action_value:\n",
    "            result = action_value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Vs_copy = dict(test_Vs)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 1.08)\n",
    "assert test_Vs == test_Vs_copy, \"please do not change state_values in get_new_state_value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine everything we wrote into a working value iteration algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, num_iter, gamma, min_difference):\n",
    "    # initialize V(s)\n",
    "    state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values using the functions you defined above.\n",
    "        # It must be a dict {state : float V_new(state)}\n",
    "        new_state_values = {state : get_new_state_value(mdp, state_values, state, gamma) for state in mdp.get_all_states()}\n",
    "\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = max(abs(new_state_values[s] - state_values[s])\n",
    "                   for s in mdp.get_all_states())\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   \" % (i, diff), end=\"\")\n",
    "        print('   '.join(\"V(%s) = %.3f\" % (s, v) for s, v in state_values.items()))\n",
    "        state_values = new_state_values\n",
    "\n",
    "        if diff < min_difference:\n",
    "            print(\"Terminated\")\n",
    "            break\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 3.50000   |   V(s0) = 0.000   V(s1) = 0.000   V(s2) = 0.000\n",
      "iter    1   |   diff: 0.64500   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.000\n",
      "iter    2   |   diff: 0.58050   |   V(s0) = 0.000   V(s1) = 3.815   V(s2) = 0.645\n",
      "iter    3   |   diff: 0.43582   |   V(s0) = 0.581   V(s1) = 3.959   V(s2) = 0.962\n",
      "iter    4   |   diff: 0.30634   |   V(s0) = 0.866   V(s1) = 4.395   V(s2) = 1.272\n",
      "iter    5   |   diff: 0.27571   |   V(s0) = 1.145   V(s1) = 4.670   V(s2) = 1.579\n",
      "iter    6   |   diff: 0.24347   |   V(s0) = 1.421   V(s1) = 4.926   V(s2) = 1.838\n",
      "iter    7   |   diff: 0.21419   |   V(s0) = 1.655   V(s1) = 5.169   V(s2) = 2.075\n",
      "iter    8   |   diff: 0.19277   |   V(s0) = 1.868   V(s1) = 5.381   V(s2) = 2.290\n",
      "iter    9   |   diff: 0.17327   |   V(s0) = 2.061   V(s1) = 5.573   V(s2) = 2.481\n",
      "iter   10   |   diff: 0.15569   |   V(s0) = 2.233   V(s1) = 5.746   V(s2) = 2.654\n",
      "iter   11   |   diff: 0.14012   |   V(s0) = 2.389   V(s1) = 5.902   V(s2) = 2.810\n",
      "iter   12   |   diff: 0.12610   |   V(s0) = 2.529   V(s1) = 6.042   V(s2) = 2.950\n",
      "iter   13   |   diff: 0.11348   |   V(s0) = 2.655   V(s1) = 6.168   V(s2) = 3.076\n",
      "iter   14   |   diff: 0.10213   |   V(s0) = 2.769   V(s1) = 6.282   V(s2) = 3.190\n",
      "iter   15   |   diff: 0.09192   |   V(s0) = 2.871   V(s1) = 6.384   V(s2) = 3.292\n",
      "iter   16   |   diff: 0.08272   |   V(s0) = 2.963   V(s1) = 6.476   V(s2) = 3.384\n",
      "iter   17   |   diff: 0.07445   |   V(s0) = 3.045   V(s1) = 6.558   V(s2) = 3.467\n",
      "iter   18   |   diff: 0.06701   |   V(s0) = 3.120   V(s1) = 6.633   V(s2) = 3.541\n",
      "iter   19   |   diff: 0.06031   |   V(s0) = 3.187   V(s1) = 6.700   V(s2) = 3.608\n",
      "iter   20   |   diff: 0.05428   |   V(s0) = 3.247   V(s1) = 6.760   V(s2) = 3.668\n",
      "iter   21   |   diff: 0.04885   |   V(s0) = 3.301   V(s1) = 6.814   V(s2) = 3.723\n",
      "iter   22   |   diff: 0.04396   |   V(s0) = 3.350   V(s1) = 6.863   V(s2) = 3.771\n",
      "iter   23   |   diff: 0.03957   |   V(s0) = 3.394   V(s1) = 6.907   V(s2) = 3.815\n",
      "iter   24   |   diff: 0.03561   |   V(s0) = 3.434   V(s1) = 6.947   V(s2) = 3.855\n",
      "iter   25   |   diff: 0.03205   |   V(s0) = 3.469   V(s1) = 6.982   V(s2) = 3.891\n",
      "iter   26   |   diff: 0.02884   |   V(s0) = 3.502   V(s1) = 7.014   V(s2) = 3.923\n",
      "iter   27   |   diff: 0.02596   |   V(s0) = 3.530   V(s1) = 7.043   V(s2) = 3.951\n",
      "iter   28   |   diff: 0.02336   |   V(s0) = 3.556   V(s1) = 7.069   V(s2) = 3.977\n",
      "iter   29   |   diff: 0.02103   |   V(s0) = 3.580   V(s1) = 7.093   V(s2) = 4.001\n",
      "iter   30   |   diff: 0.01892   |   V(s0) = 3.601   V(s1) = 7.114   V(s2) = 4.022\n",
      "iter   31   |   diff: 0.01703   |   V(s0) = 3.620   V(s1) = 7.133   V(s2) = 4.041\n",
      "iter   32   |   diff: 0.01533   |   V(s0) = 3.637   V(s1) = 7.150   V(s2) = 4.058\n",
      "iter   33   |   diff: 0.01380   |   V(s0) = 3.652   V(s1) = 7.165   V(s2) = 4.073\n",
      "iter   34   |   diff: 0.01242   |   V(s0) = 3.666   V(s1) = 7.179   V(s2) = 4.087\n",
      "iter   35   |   diff: 0.01117   |   V(s0) = 3.678   V(s1) = 7.191   V(s2) = 4.099\n",
      "iter   36   |   diff: 0.01006   |   V(s0) = 3.689   V(s1) = 7.202   V(s2) = 4.110\n",
      "iter   37   |   diff: 0.00905   |   V(s0) = 3.699   V(s1) = 7.212   V(s2) = 4.121\n",
      "iter   38   |   diff: 0.00815   |   V(s0) = 3.708   V(s1) = 7.221   V(s2) = 4.130\n",
      "iter   39   |   diff: 0.00733   |   V(s0) = 3.717   V(s1) = 7.230   V(s2) = 4.138\n",
      "iter   40   |   diff: 0.00660   |   V(s0) = 3.724   V(s1) = 7.237   V(s2) = 4.145\n",
      "iter   41   |   diff: 0.00594   |   V(s0) = 3.731   V(s1) = 7.244   V(s2) = 4.152\n",
      "iter   42   |   diff: 0.00534   |   V(s0) = 3.736   V(s1) = 7.249   V(s2) = 4.158\n",
      "iter   43   |   diff: 0.00481   |   V(s0) = 3.742   V(s1) = 7.255   V(s2) = 4.163\n",
      "iter   44   |   diff: 0.00433   |   V(s0) = 3.747   V(s1) = 7.260   V(s2) = 4.168\n",
      "iter   45   |   diff: 0.00390   |   V(s0) = 3.751   V(s1) = 7.264   V(s2) = 4.172\n",
      "iter   46   |   diff: 0.00351   |   V(s0) = 3.755   V(s1) = 7.268   V(s2) = 4.176\n",
      "iter   47   |   diff: 0.00316   |   V(s0) = 3.758   V(s1) = 7.271   V(s2) = 4.179\n",
      "iter   48   |   diff: 0.00284   |   V(s0) = 3.762   V(s1) = 7.275   V(s2) = 4.183\n",
      "iter   49   |   diff: 0.00256   |   V(s0) = 3.764   V(s1) = 7.277   V(s2) = 4.185\n",
      "iter   50   |   diff: 0.00230   |   V(s0) = 3.767   V(s1) = 7.280   V(s2) = 4.188\n",
      "iter   51   |   diff: 0.00207   |   V(s0) = 3.769   V(s1) = 7.282   V(s2) = 4.190\n",
      "iter   52   |   diff: 0.00186   |   V(s0) = 3.771   V(s1) = 7.284   V(s2) = 4.192\n",
      "iter   53   |   diff: 0.00168   |   V(s0) = 3.773   V(s1) = 7.286   V(s2) = 4.194\n",
      "iter   54   |   diff: 0.00151   |   V(s0) = 3.775   V(s1) = 7.288   V(s2) = 4.196\n",
      "iter   55   |   diff: 0.00136   |   V(s0) = 3.776   V(s1) = 7.289   V(s2) = 4.197\n",
      "iter   56   |   diff: 0.00122   |   V(s0) = 3.778   V(s1) = 7.291   V(s2) = 4.199\n",
      "iter   57   |   diff: 0.00110   |   V(s0) = 3.779   V(s1) = 7.292   V(s2) = 4.200\n",
      "iter   58   |   diff: 0.00099   |   V(s0) = 3.780   V(s1) = 7.293   V(s2) = 4.201\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9            # discount for MDP\n",
    "num_iter = 100         # maximum iterations, excluding initialization\n",
    "# stop VI if new values are this close to old values (or closer)\n",
    "min_difference = 0.001\n",
    "\n",
    "state_values = value_iteration(mdp, num_iter, gamma, min_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    display(plot_graph_with_state_values(mdp, state_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state values: {'s0': 3.7810348735476405, 's1': 7.294006423867229, 's2': 4.202140275227048}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final state values:\", state_values)\n",
    "\n",
    "assert abs(state_values['s0'] - 3.781) < 0.01\n",
    "assert abs(state_values['s1'] - 7.294) < 0.01\n",
    "assert abs(state_values['s2'] - 4.202) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    " \n",
    "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return None\n",
    "    result = None\n",
    "    resulted_action = None\n",
    "    for action in mdp.get_possible_actions(state):\n",
    "        action_value = get_action_value(mdp, state_values, state, action, gamma)\n",
    "        if result == None or result < action_value:\n",
    "            result = action_value\n",
    "            resulted_action = action\n",
    "    return resulted_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
    "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
    "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    try:\n",
    "        display(plot_graph_optimal_strategy_and_state_values(mdp, state_values))\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Run the cell that starts with \\\"%%writefile mdp_get_action_value.py\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward:  0.4547\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "\n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert(0.40 < np.mean(rewards) < 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, state_values=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
    "    state_values = state_values or {s: 0 for s in mdp.get_all_states()}\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "        new_state_values = {state : get_new_state_value(mdp, state_values, state, gamma) for state in mdp.get_all_states()}\n",
    "\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = max(abs(new_state_values[s] - state_values[s])\n",
    "                   for s in mdp.get_all_states())\n",
    "\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \" %\n",
    "              (i, diff, new_state_values[mdp._initial_state]))\n",
    "\n",
    "        state_values = new_state_values\n",
    "        if diff < min_difference:\n",
    "            break\n",
    "\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    }
   ],
   "source": [
    "state_values = value_iteration(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "*HFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "*FFH\n",
      "HFFG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F*FH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H*FG\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF*G\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = mdp.reset()\n",
    "mdp.render()\n",
    "for t in range(100):\n",
    "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
    "    print(a, end='\\n\\n')\n",
    "    s, r, done, _ = mdp.step(a)\n",
    "    mdp.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize!\n",
    "\n",
    "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def draw_policy(mdp, state_values):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    h, w = mdp.desc.shape\n",
    "    states = sorted(mdp.get_all_states())\n",
    "    V = np.array([state_values[s] for s in states])\n",
    "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
    "    plt.imshow(V.reshape(w, h), cmap='gray', interpolation='none', clim=(0, 1))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(h)-.5)\n",
    "    ax.set_yticks(np.arange(w)-.5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    Y, X = np.mgrid[0:4, 0:4]\n",
    "    a2uv = {'left': (-1, 0), 'down': (0, -1), 'right': (1, 0), 'up': (-1, 0)}\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            plt.text(x, y, str(mdp.desc[y, x].item()),\n",
    "                     color='g', size=12,  verticalalignment='center',\n",
    "                     horizontalalignment='center', fontweight='bold')\n",
    "            a = Pi[y, x]\n",
    "            if a is None:\n",
    "                continue\n",
    "            u, v = a2uv[a]\n",
    "            plt.arrow(x, y, u*.3, -v*.3, color='m',\n",
    "                      head_width=0.1, head_length=0.1)\n",
    "    plt.grid(color='b', lw=2, ls='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 0\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 1\n",
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 2\n",
      "iter    0   |   diff: 0.81000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 3\n",
      "iter    0   |   diff: 0.72900   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 4\n",
      "iter    0   |   diff: 0.65610   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 5\n",
      "iter    0   |   diff: 0.59049   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 6\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 7\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 8\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 9\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 29\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.198 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "mdp = FrozenLakeEnv(map_name='8x8', slip_chance=0.1)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "average reward:  1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.62330   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.50487   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.40894   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.34868   |   V(start): 0.349 \n",
      "iter    6   |   diff: 0.06529   |   V(start): 0.410 \n",
      "iter    7   |   diff: 0.05832   |   V(start): 0.468 \n",
      "iter    8   |   diff: 0.01139   |   V(start): 0.480 \n",
      "iter    9   |   diff: 0.00764   |   V(start): 0.487 \n",
      "iter   10   |   diff: 0.00164   |   V(start): 0.489 \n",
      "iter   11   |   diff: 0.00094   |   V(start): 0.490 \n",
      "iter   12   |   diff: 0.00022   |   V(start): 0.490 \n",
      "iter   13   |   diff: 0.00011   |   V(start): 0.490 \n",
      "iter   14   |   diff: 0.00003   |   V(start): 0.490 \n",
      "iter   15   |   diff: 0.00001   |   V(start): 0.490 \n",
      "iter   16   |   diff: 0.00000   |   V(start): 0.490 \n",
      "average reward:  0.872\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.39867   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.26910   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.18164   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.14013   |   V(start): 0.140 \n",
      "iter    6   |   diff: 0.07028   |   V(start): 0.199 \n",
      "iter    7   |   diff: 0.06030   |   V(start): 0.260 \n",
      "iter    8   |   diff: 0.02594   |   V(start): 0.285 \n",
      "iter    9   |   diff: 0.01918   |   V(start): 0.305 \n",
      "iter   10   |   diff: 0.00858   |   V(start): 0.313 \n",
      "iter   11   |   diff: 0.00560   |   V(start): 0.319 \n",
      "iter   12   |   diff: 0.00260   |   V(start): 0.321 \n",
      "iter   13   |   diff: 0.00159   |   V(start): 0.323 \n",
      "iter   14   |   diff: 0.00076   |   V(start): 0.324 \n",
      "iter   15   |   diff: 0.00045   |   V(start): 0.324 \n",
      "iter   16   |   diff: 0.00022   |   V(start): 0.324 \n",
      "iter   17   |   diff: 0.00012   |   V(start): 0.325 \n",
      "iter   18   |   diff: 0.00006   |   V(start): 0.325 \n",
      "iter   19   |   diff: 0.00003   |   V(start): 0.325 \n",
      "iter   20   |   diff: 0.00002   |   V(start): 0.325 \n",
      "iter   21   |   diff: 0.00001   |   V(start): 0.325 \n",
      "average reward:  0.665\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.24186   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.19349   |   V(start): 0.000 \n",
      "iter    6   |   diff: 0.15325   |   V(start): 0.000 \n",
      "iter    7   |   diff: 0.12288   |   V(start): 0.000 \n",
      "iter    8   |   diff: 0.09930   |   V(start): 0.000 \n",
      "iter    9   |   diff: 0.08037   |   V(start): 0.000 \n",
      "iter   10   |   diff: 0.06426   |   V(start): 0.000 \n",
      "iter   11   |   diff: 0.05129   |   V(start): 0.000 \n",
      "iter   12   |   diff: 0.04330   |   V(start): 0.000 \n",
      "iter   13   |   diff: 0.03802   |   V(start): 0.033 \n",
      "iter   14   |   diff: 0.03332   |   V(start): 0.058 \n",
      "iter   15   |   diff: 0.02910   |   V(start): 0.087 \n",
      "iter   16   |   diff: 0.01855   |   V(start): 0.106 \n",
      "iter   17   |   diff: 0.01403   |   V(start): 0.120 \n",
      "iter   18   |   diff: 0.00810   |   V(start): 0.128 \n",
      "iter   19   |   diff: 0.00555   |   V(start): 0.133 \n",
      "iter   20   |   diff: 0.00321   |   V(start): 0.137 \n",
      "iter   21   |   diff: 0.00247   |   V(start): 0.138 \n",
      "iter   22   |   diff: 0.00147   |   V(start): 0.139 \n",
      "iter   23   |   diff: 0.00104   |   V(start): 0.140 \n",
      "iter   24   |   diff: 0.00058   |   V(start): 0.140 \n",
      "iter   25   |   diff: 0.00036   |   V(start): 0.141 \n",
      "iter   26   |   diff: 0.00024   |   V(start): 0.141 \n",
      "iter   27   |   diff: 0.00018   |   V(start): 0.141 \n",
      "iter   28   |   diff: 0.00012   |   V(start): 0.141 \n",
      "iter   29   |   diff: 0.00007   |   V(start): 0.141 \n",
      "iter   30   |   diff: 0.00004   |   V(start): 0.141 \n",
      "iter   31   |   diff: 0.00003   |   V(start): 0.141 \n",
      "iter   32   |   diff: 0.00001   |   V(start): 0.141 \n",
      "iter   33   |   diff: 0.00001   |   V(start): 0.141 \n",
      "average reward:  0.759\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1 - find an MDP for which value iteration takes long to converge  (2+ pts)\n",
    "\n",
    "When we ran value iteration on the small frozen lake problem, the last iteration where an action changed was iteration 6--i.e., value iteration computed the optimal policy at iteration 6. Are there any guarantees regarding how many iterations it'll take value iteration to compute the optimal policy? There are no such guarantees without additional assumptions--we can construct the MDP in such a way that the greedy policy will change after arbitrarily many iterations.\n",
    "\n",
    "Your task: define an MDP with at most 3 states and 2 actions, such that when you run value iteration, the optimal action changes at iteration >= 50. Use discount=0.95. (However, note that the discount doesn't matter here--you can construct an appropriate MDP with any discount.)\n",
    "\n",
    "Note: value function must change at least once after iteration >=50, not necessarily change on every iteration till >=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s2': 1},\n",
    "        'a1': {'s0': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s2': 1}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s1': 1}\n",
    "    }\n",
    "}\n",
    "\n",
    "rewards = {\n",
    "    's0': {'a1': {'s0': 0}},\n",
    "    's1': {'a0': {'s2': 1.07}},\n",
    "    's2': {'a0': {'s1': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "from numpy import random\n",
    "mdp = MDP(transition_probs, rewards, initial_state=random.choice(tuple(transition_probs.keys())))\n",
    "# Feel free to change the initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 0\n",
      "iter    0   |   diff: 1.07000   |   V(start): 1.070 \n",
      "{'s0': 0.0, 's1': 1.07, 's2': -1.0}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 1\n",
      "iter    0   |   diff: 1.01650   |   V(start): 0.120 \n",
      "{'s0': 0.0, 's1': 0.1200000000000001, 's2': 0.01649999999999996}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 2\n",
      "iter    0   |   diff: 0.96567   |   V(start): 1.086 \n",
      "{'s0': 0.01567499999999996, 's1': 1.085675, 's2': -0.8859999999999999}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 3\n",
      "iter    0   |   diff: 0.91739   |   V(start): 0.228 \n",
      "{'s0': 0.014891249999999962, 's1': 0.22830000000000017, 's2': 0.03139124999999998}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 4\n",
      "iter    0   |   diff: 0.87152   |   V(start): 1.100 \n",
      "{'s0': 0.029821687499999982, 's1': 1.0998216875, 's2': -0.7831149999999998}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 5\n",
      "iter    0   |   diff: 0.82795   |   V(start): 0.326 \n",
      "{'s0': 0.028330603124999982, 's1': 0.3260407500000003, 's2': 0.04483060312499987}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 6\n",
      "iter    0   |   diff: 0.78655   |   V(start): 1.113 \n",
      "{'s0': 0.04258907296874987, 's1': 1.11258907296875, 's2': -0.6902612874999997}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 7\n",
      "iter    0   |   diff: 0.74722   |   V(start): 0.414 \n",
      "{'s0': 0.040459619320312376, 's1': 0.41425177687500037, 's2': 0.05695961932031235}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 8\n",
      "iter    0   |   diff: 0.70986   |   V(start): 1.124 \n",
      "{'s0': 0.05411163835429673, 's1': 1.1241116383542968, 's2': -0.6064608119687497}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 9\n",
      "iter    0   |   diff: 0.67437   |   V(start): 0.494 \n",
      "{'s0': 0.05140605643658189, 's1': 0.49386222862968787, 's2': 0.06790605643658187}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 10\n",
      "iter    0   |   diff: 0.64065   |   V(start): 1.135 \n",
      "{'s0': 0.06451075361475278, 's1': 1.134510753614753, 's2': -0.5308308828017965}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 11\n",
      "iter    0   |   diff: 0.60862   |   V(start): 0.566 \n",
      "{'s0': 0.06128521593401514, 's1': 0.5657106613382934, 's2': 0.07778521593401533}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 12\n",
      "iter    0   |   diff: 0.57819   |   V(start): 1.144 \n",
      "{'s0': 0.07389595513731456, 's1': 1.1438959551373147, 's2': -0.46257487172862133}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 13\n",
      "iter    0   |   diff: 0.54928   |   V(start): 0.631 \n",
      "{'s0': 0.07020115738044883, 's1': 0.6305538718578099, 's2': 0.08670115738044881}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 14\n",
      "iter    0   |   diff: 0.52181   |   V(start): 1.152 \n",
      "{'s0': 0.08236609951142637, 's1': 1.1523660995114264, 's2': -0.40097382173508067}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 15\n",
      "iter    0   |   diff: 0.49572   |   V(start): 0.689 \n",
      "{'s0': 0.07824779453585505, 's1': 0.6890748693516735, 's2': 0.09474779453585502}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 16\n",
      "iter    0   |   diff: 0.47094   |   V(start): 1.160 \n",
      "{'s0': 0.09001040480906226, 's1': 1.1600104048090623, 's2': -0.3453788741159102}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 17\n",
      "iter    0   |   diff: 0.44739   |   V(start): 0.742 \n",
      "{'s0': 0.08550988456860914, 's1': 0.7418900695898853, 's2': 0.10200988456860904}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 18\n",
      "iter    0   |   diff: 0.42502   |   V(start): 1.167 \n",
      "{'s0': 0.09690939034017859, 's1': 1.1669093903401786, 's2': -0.29520443388960893}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 19\n",
      "iter    0   |   diff: 0.40377   |   V(start): 0.790 \n",
      "{'s0': 0.09206392082316965, 's1': 0.7895557878048716, 's2': 0.10856392082316968}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 20\n",
      "iter    0   |   diff: 0.38358   |   V(start): 1.173 \n",
      "{'s0': 0.10313572478201119, 's1': 1.1731357247820113, 's2': -0.24992200158537203}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 21\n",
      "iter    0   |   diff: 0.36440   |   V(start): 0.833 \n",
      "{'s0': 0.09797893854291062, 's1': 0.8325740984938966, 's2': 0.1144789385429108}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 22\n",
      "iter    0   |   diff: 0.34618   |   V(start): 1.179 \n",
      "{'s0': 0.10875499161576525, 's1': 1.1787549916157654, 's2': -0.2090546064307982}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 23\n",
      "iter    0   |   diff: 0.32887   |   V(start): 0.871 \n",
      "{'s0': 0.10331724203497698, 's1': 0.8713981238907418, 's2': 0.11981724203497701}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 24\n",
      "iter    0   |   diff: 0.31243   |   V(start): 1.184 \n",
      "{'s0': 0.11382637993322815, 's1': 1.1838263799332283, 's2': -0.17217178230379537}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 25\n",
      "iter    0   |   diff: 0.29681   |   V(start): 0.906 \n",
      "{'s0': 0.10813506093656675, 's1': 0.9064368068113945, 's2': 0.12463506093656673}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 26\n",
      "iter    0   |   diff: 0.28197   |   V(start): 1.188 \n",
      "{'s0': 0.1184033078897384, 's1': 1.1884033078897385, 's2': -0.13888503352917525}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 27\n",
      "iter    0   |   diff: 0.26787   |   V(start): 0.938 \n",
      "{'s0': 0.11248314249525147, 's1': 0.9380592181472835, 's2': 0.12898314249525145}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 28\n",
      "iter    0   |   diff: 0.25447   |   V(start): 1.193 \n",
      "{'s0': 0.12253398537048887, 's1': 1.1925339853704888, 's2': -0.10884374276008069}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 29\n",
      "iter    0   |   diff: 0.24175   |   V(start): 0.967 \n",
      "{'s0': 0.11640728610196442, 's1': 0.9665984443779234, 's2': 0.13290728610196423}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 30\n",
      "iter    0   |   diff: 0.22966   |   V(start): 1.196 \n",
      "{'s0': 0.12626192179686602, 's1': 1.1962619217968662, 's2': -0.08173147784097279}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 31\n",
      "iter    0   |   diff: 0.21818   |   V(start): 0.992 \n",
      "{'s0': 0.11994882570702271, 's1': 0.9923550960510759, 's2': 0.13644882570702288}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 32\n",
      "iter    0   |   diff: 0.20727   |   V(start): 1.200 \n",
      "{'s0': 0.12962638442167174, 's1': 1.1996263844216717, 's2': -0.05726265875147796}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 33\n",
      "iter    0   |   diff: 0.19691   |   V(start): 1.016 \n",
      "{'s0': 0.12314506520058814, 's1': 1.015600474186096, 's2': 0.13964506520058806}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 34\n",
      "iter    0   |   diff: 0.18706   |   V(start): 1.203 \n",
      "{'s0': 0.13266281194055865, 's1': 1.2026628119405587, 's2': -0.0351795495232089}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 35\n",
      "iter    0   |   diff: 0.17771   |   V(start): 1.037 \n",
      "{'s0': 0.1260296713435307, 's1': 1.0365794279529517, 's2': 0.14252967134353067}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 36\n",
      "iter    0   |   diff: 0.16882   |   V(start): 1.205 \n",
      "{'s0': 0.13540318777635413, 's1': 1.2054031877763542, 's2': -0.015249543444695979}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 37\n",
      "iter    0   |   diff: 0.16038   |   V(start): 1.056 \n",
      "{'s0': 0.1286330283875364, 's1': 1.0555129337275388, 's2': 0.1451330283875365}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 38\n",
      "iter    0   |   diff: 0.15236   |   V(start): 1.208 \n",
      "{'s0': 0.13787637696815966, 's1': 1.2078763769681597, 's2': 0.00273728704116194}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 39\n",
      "iter    0   |   diff: 0.14475   |   V(start): 1.073 \n",
      "{'s0': 0.13098255811975168, 's1': 1.072600422689104, 's2': 0.14748255811975164}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 40\n",
      "iter    0   |   diff: 0.13751   |   V(start): 1.210 \n",
      "{'s0': 0.14010843021376404, 's1': 1.2101084302137641, 's2': 0.018970401554648797}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 41\n",
      "iter    0   |   diff: 0.13063   |   V(start): 1.088 \n",
      "{'s0': 0.13310300870307584, 's1': 1.0880218814769165, 's2': 0.14960300870307597}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 42\n",
      "iter    0   |   diff: 0.12410   |   V(start): 1.212 \n",
      "{'s0': 0.14212285826792218, 's1': 1.2121228582679222, 's2': 0.03362078740307051}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 43\n",
      "iter    0   |   diff: 0.11790   |   V(start): 1.102 \n",
      "{'s0': 0.13501671535452606, 's1': 1.101939748032917, 's2': 0.15151671535452604}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 44\n",
      "iter    0   |   diff: 0.11200   |   V(start): 1.214 \n",
      "{'s0': 0.14394087958679974, 's1': 1.2139408795867999, 's2': 0.04684276063127113}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 45\n",
      "iter    0   |   diff: 0.10640   |   V(start): 1.115 \n",
      "{'s0': 0.13674383560745976, 's1': 1.1145006225997076, 's2': 0.1532438356074599}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 46\n",
      "iter    0   |   diff: 0.10108   |   V(start): 1.216 \n",
      "{'s0': 0.1455816438270869, 's1': 1.215581643827087, 's2': 0.05877559146972211}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 47\n",
      "iter    0   |   diff: 0.09603   |   V(start): 1.126 \n",
      "{'s0': 0.13830256163573257, 's1': 1.125836811896236, 's2': 0.1548025616357327}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 48\n",
      "iter    0   |   diff: 0.09123   |   V(start): 1.217 \n",
      "{'s0': 0.14706243355394605, 's1': 1.2170624335539462, 's2': 0.06954497130142423}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 49\n",
      "iter    0   |   diff: 0.08666   |   V(start): 1.136 \n",
      "{'s0': 0.13970931187624874, 's1': 1.1360677227363531, 's2': 0.15620931187624887}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 50\n",
      "iter    0   |   diff: 0.08233   |   V(start): 1.218 \n",
      "{'s0': 0.1483988462824364, 's1': 1.2183988462824364, 's2': 0.07926433659953536}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 51\n",
      "iter    0   |   diff: 0.07821   |   V(start): 1.145 \n",
      "{'s0': 0.14097890396831458, 's1': 1.1453011197695586, 's2': 0.15747890396831465}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 52\n",
      "iter    0   |   diff: 0.07430   |   V(start): 1.220 \n",
      "{'s0': 0.1496049587698989, 's1': 1.219604958769899, 's2': 0.08803606378108064}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 53\n",
      "iter    0   |   diff: 0.07059   |   V(start): 1.154 \n",
      "{'s0': 0.14212471083140396, 's1': 1.1536342605920267, 's2': 0.15862471083140384}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 54\n",
      "iter    0   |   diff: 0.06706   |   V(start): 1.221 \n",
      "{'s0': 0.15069347528983365, 's1': 1.2206934752898337, 's2': 0.09595254756242522}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 55\n",
      "iter    0   |   diff: 0.06371   |   V(start): 1.161 \n",
      "{'s0': 0.14315880152534197, 's1': 1.161154920184304, 's2': 0.15965880152534195}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 56\n",
      "iter    0   |   diff: 0.06052   |   V(start): 1.222 \n",
      "{'s0': 0.15167586144907486, 's1': 1.221675861449075, 's2': 0.10309717417508879}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 57\n",
      "iter    0   |   diff: 0.05749   |   V(start): 1.168 \n",
      "{'s0': 0.1440920683766211, 's1': 1.1679423154663344, 's2': 0.16059206837662132}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 58\n",
      "iter    0   |   diff: 0.05462   |   V(start): 1.223 \n",
      "{'s0': 0.15256246495779024, 's1': 1.2225624649577904, 's2': 0.10954519969301768}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 59\n",
      "iter    0   |   diff: 0.05189   |   V(start): 1.174 \n",
      "{'s0': 0.14493434170990072, 's1': 1.1740679397083669, 's2': 0.1614343417099009}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 60\n",
      "iter    0   |   diff: 0.04929   |   V(start): 1.223 \n",
      "{'s0': 0.15336262462440584, 's1': 1.2233626246244058, 's2': 0.11536454272294838}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 61\n",
      "iter    0   |   diff: 0.04683   |   V(start): 1.180 \n",
      "{'s0': 0.14569449339318555, 's1': 1.179596315586801, 's2': 0.16219449339318537}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 62\n",
      "iter    0   |   diff: 0.04449   |   V(start): 1.224 \n",
      "{'s0': 0.15408476872352608, 's1': 1.2240847687235261, 's2': 0.12061649980746081}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 63\n",
      "iter    0   |   diff: 0.04226   |   V(start): 1.185 \n",
      "{'s0': 0.14638053028734976, 's1': 1.1845856748170878, 's2': 0.16288053028734972}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 64\n",
      "iter    0   |   diff: 0.04015   |   V(start): 1.225 \n",
      "{'s0': 0.15473650377298223, 's1': 1.2247365037729823, 's2': 0.12535639107623342}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 65\n",
      "iter    0   |   diff: 0.03814   |   V(start): 1.189 \n",
      "{'s0': 0.1469996785843331, 's1': 1.1890885715224218, 's2': 0.163499678584333}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 66\n",
      "iter    0   |   diff: 0.03624   |   V(start): 1.225 \n",
      "{'s0': 0.15532469465511636, 's1': 1.2253246946551164, 's2': 0.1296341429463006}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 67\n",
      "iter    0   |   diff: 0.03442   |   V(start): 1.193 \n",
      "{'s0': 0.14755845992236055, 's1': 1.1931524357989856, 's2': 0.16405845992236046}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 68\n",
      "iter    0   |   diff: 0.03270   |   V(start): 1.226 \n",
      "{'s0': 0.15585553692624243, 's1': 1.2258555369262425, 's2': 0.13349481400903618}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 69\n",
      "iter    0   |   diff: 0.03107   |   V(start): 1.197 \n",
      "{'s0': 0.1480627600799303, 's1': 1.1968200733085843, 's2': 0.16456276007993043}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 70\n",
      "iter    0   |   diff: 0.02951   |   V(start): 1.226 \n",
      "{'s0': 0.1563346220759339, 's1': 1.226334622075934, 's2': 0.13697906964315498}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 71\n",
      "iter    0   |   diff: 0.02804   |   V(start): 1.200 \n",
      "{'s0': 0.1485178909721372, 's1': 1.2001301161609974, 's2': 0.16501789097213715}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 72\n",
      "iter    0   |   diff: 0.02664   |   V(start): 1.227 \n",
      "{'s0': 0.15676699642353029, 's1': 1.2267669964235304, 's2': 0.14012361035294751}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 73\n",
      "iter    0   |   diff: 0.02531   |   V(start): 1.203 \n",
      "{'s0': 0.14892864660235378, 's1': 1.2031174298353002, 's2': 0.1654286466023538}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 74\n",
      "iter    0   |   diff: 0.02404   |   V(start): 1.227 \n",
      "{'s0': 0.15715721427223608, 's1': 1.2271572142722362, 's2': 0.14296155834353508}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 75\n",
      "iter    0   |   diff: 0.02284   |   V(start): 1.206 \n",
      "{'s0': 0.14929935355862428, 's1': 1.2058134804263583, 's2': 0.1657993535586244}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 76\n",
      "iter    0   |   diff: 0.02170   |   V(start): 1.228 \n",
      "{'s0': 0.1575093858806932, 's1': 1.2275093858806931, 's2': 0.14552280640504023}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 77\n",
      "iter    0   |   diff: 0.02061   |   V(start): 1.208 \n",
      "{'s0': 0.14963391658665853, 's1': 1.2082466660847884, 's2': 0.16613391658665844}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 78\n",
      "iter    0   |   diff: 0.01958   |   V(start): 1.228 \n",
      "{'s0': 0.1578272207573255, 's1': 1.2278272207573255, 's2': 0.14783433278054892}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 79\n",
      "iter    0   |   diff: 0.01860   |   V(start): 1.210 \n",
      "{'s0': 0.14993585971945922, 's1': 1.2104426161415216, 's2': 0.1664358597194593}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 80\n",
      "iter    0   |   diff: 0.01767   |   V(start): 1.228 \n",
      "{'s0': 0.15811406673348632, 's1': 1.2281140667334864, 's2': 0.14992048533444557}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 81\n",
      "iter    0   |   diff: 0.01679   |   V(start): 1.212 \n",
      "{'s0': 0.150208363396812, 's1': 1.2124244610677233, 's2': 0.16670836339681205}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 82\n",
      "iter    0   |   diff: 0.01595   |   V(start): 1.228 \n",
      "{'s0': 0.15837294522697146, 's1': 1.2283729452269716, 's2': 0.15180323801433704}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 83\n",
      "iter    0   |   diff: 0.01515   |   V(start): 1.214 \n",
      "{'s0': 0.15045429796562287, 's1': 1.2142130761136203, 's2': 0.1669542979656229}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 84\n",
      "iter    0   |   diff: 0.01439   |   V(start): 1.229 \n",
      "{'s0': 0.15860658306734174, 's1': 1.2286065830673418, 's2': 0.1535024223079393}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 85\n",
      "iter    0   |   diff: 0.01367   |   V(start): 1.216 \n",
      "{'s0': 0.15067625391397466, 's1': 1.2158273011925425, 's2': 0.16717625391397473}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 86\n",
      "iter    0   |   diff: 0.01299   |   V(start): 1.229 \n",
      "{'s0': 0.15881744121827598, 's1': 1.228817441218276, 's2': 0.15503593613291522}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 87\n",
      "iter    0   |   diff: 0.01234   |   V(start): 1.217 \n",
      "{'s0': 0.15087656915736217, 's1': 1.2172841393262694, 's2': 0.1673765691573621}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 88\n",
      "iter    0   |   diff: 0.01172   |   V(start): 1.229 \n",
      "{'s0': 0.159007740699494, 's1': 1.2290077406994941, 's2': 0.156419932359956}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 89\n",
      "iter    0   |   diff: 0.01114   |   V(start): 1.219 \n",
      "{'s0': 0.15105735366451928, 's1': 1.2185989357419582, 's2': 0.1675573536645194}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 90\n",
      "iter    0   |   diff: 0.01058   |   V(start): 1.229 \n",
      "{'s0': 0.15917948598129342, 's1': 1.2291794859812935, 's2': 0.15766898895486015}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 91\n",
      "iter    0   |   diff: 0.01005   |   V(start): 1.220 \n",
      "{'s0': 0.15122051168222875, 's1': 1.219785539507117, 's2': 0.16772051168222868}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 92\n",
      "iter    0   |   diff: 0.00955   |   V(start): 1.229 \n",
      "{'s0': 0.15933448609811723, 's1': 1.2293344860981172, 's2': 0.15879626253176116}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 93\n",
      "iter    0   |   diff: 0.00907   |   V(start): 1.221 \n",
      "{'s0': 0.15136776179321138, 's1': 1.2208564494051732, 's2': 0.1678677617932114}\n",
      "N actions changed = 1 \n",
      "\n",
      "after iteration 94\n",
      "iter    0   |   diff: 0.00862   |   V(start): 1.229 \n",
      "{'s0': 0.1594743737035508, 's1': 1.229474373703551, 's2': 0.15981362693491463}\n",
      "N actions changed = 0 \n",
      "\n",
      "after iteration 95\n",
      "iter    0   |   diff: 0.00819   |   V(start): 1.222 \n",
      "{'s0': 0.1518229455881689, 's1': 1.221822945588169, 's2': 0.16800065501837325}\n",
      "N actions changed = 0 \n",
      "\n",
      "after iteration 96\n",
      "iter    0   |   diff: 0.00778   |   V(start): 1.230 \n",
      "{'s0': 0.15960062226745458, 's1': 1.2296006222674547, 's2': 0.1607317983087606}\n",
      "N actions changed = 0 \n",
      "\n",
      "after iteration 97\n",
      "iter    0   |   diff: 0.00739   |   V(start): 1.223 \n",
      "{'s0': 0.15269520839332257, 's1': 1.2226952083933227, 's2': 0.16812059115408196}\n",
      "N actions changed = 0 \n",
      "\n",
      "after iteration 98\n",
      "iter    0   |   diff: 0.00702   |   V(start): 1.230 \n",
      "{'s0': 0.15971456159637784, 's1': 1.2297145615963778, 's2': 0.16156044797365654}\n",
      "N actions changed = 0 \n",
      "\n",
      "after iteration 99\n",
      "iter    0   |   diff: 0.00667   |   V(start): 1.223 \n",
      "{'s0': 0.1534824255749737, 's1': 1.2234824255749737, 's2': 0.16822883351655893}\n",
      "N actions changed = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                   for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, 0.95, num_iter=1)\n",
    "    print(state_values)\n",
    "    new_policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                           for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "    n_changes = (policy != new_policy).sum()\n",
    "    print(\"N actions changed = %i \\n\" % n_changes)\n",
    "    policy = new_policy\n",
    "\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, we did it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2 - Policy Iteration (3+ points)\n",
    "\n",
    "Let's implement exact policy iteration (PI), which has the following pseudocode:\n",
    "\n",
    "---\n",
    "Initialize $\\pi_0$   `// random or fixed action`\n",
    "\n",
    "For $n=0, 1, 2, \\dots$\n",
    "- Compute the state-value function $V^{\\pi_{n}}$\n",
    "- Using $V^{\\pi_{n}}$, compute the state-action-value function $Q^{\\pi_{n}}$\n",
    "- Compute new policy $\\pi_{n+1}(s) = \\operatorname*{argmax}_a Q^{\\pi_{n}}(s,a)$\n",
    "---\n",
    "\n",
    "Unlike VI, policy iteration has to maintain a policy - chosen actions from all states - and estimate $V^{\\pi_{n}}$ based on this policy. It only changes policy once values converged.\n",
    "\n",
    "\n",
    "Below are a few helpers that you may or may not use in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s2': 1},\n",
    "        'a1': {'s0': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s2': 1}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s1': 1}\n",
    "    }\n",
    "}\n",
    "\n",
    "rewards = {\n",
    "    's0': {'a1': {'s0': 0}},\n",
    "    's1': {'a0': {'s2': 1.07}},\n",
    "    's2': {'a0': {'s1': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function called `compute_vpi` that computes the state-value function $V^{\\pi}$ for an arbitrary policy $\\pi$.\n",
    "\n",
    "Unlike VI, this time you must find the exact solution, not just a single iteration.\n",
    "\n",
    "Recall that $V^{\\pi}$ satisfies the following linear equation:\n",
    "$$V^{\\pi}(s) = \\sum_{s'} P(s,\\pi(s),s')[ R(s,\\pi(s),s') + \\gamma V^{\\pi}(s')]$$\n",
    "\n",
    "You'll have to solve a linear system in your code. (Find an exact solution, e.g., with `np.linalg.solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_vpi(mdp, policy, gamma):\n",
    "    \"\"\"\n",
    "    Computes V^pi(s) FOR ALL STATES under given policy.\n",
    "    :param policy: a dict of currently chosen actions {s : a}\n",
    "    :returns: a dict {state : V^pi(state) for all states}\n",
    "    \"\"\"\n",
    "    all_states = mdp.get_all_states()\n",
    "    matrix = np.zeros((len(all_states), len(all_states)))\n",
    "    vector = np.zeros(len(all_states))\n",
    "    states_indices = {state : i for i, state in enumerate(all_states)}\n",
    "    for row_index, state in enumerate(all_states):\n",
    "        state_index = states_indices[state]\n",
    "        assert(state_index == row_index)\n",
    "        matrix[row_index][state_index] -= 1\n",
    "        if (len(policy[state]) == 0):\n",
    "            continue\n",
    "        for to_state in mdp.get_next_states(state, policy[state]):\n",
    "            transition_probability = mdp.get_transition_prob(state, policy[state], to_state)\n",
    "            reward = mdp.get_reward(state, policy[state], to_state)\n",
    "            to_state_index = states_indices[to_state]\n",
    "            matrix[row_index][to_state_index] += transition_probability * gamma\n",
    "            vector[row_index] -= transition_probability * reward\n",
    "    result = np.linalg.solve(matrix, vector)\n",
    "    resulted_dict = {}\n",
    "    for index, state in enumerate(all_states):\n",
    "        resulted_dict[state] = result[index]\n",
    "    return resulted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-baa307f9a37e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m test_policy = {s: np.random.choice(\n\u001b[1;32m----> 4\u001b[1;33m     mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mnew_vpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_vpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_policy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-baa307f9a37e>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m test_policy = {s: np.random.choice(\n\u001b[1;32m----> 4\u001b[1;33m     mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mnew_vpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_vpi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_policy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "\n",
    "test_policy = {s: np.random.choice(\n",
    "    mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n",
    "new_vpi = compute_vpi(mdp, test_policy, gamma)\n",
    "\n",
    "print(new_vpi)\n",
    "\n",
    "assert type(\n",
    "    new_vpi) is dict, \"compute_vpi must return a dict {state : V^pi(state) for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've got new state values, it's time to update our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_policy(mdp, vpi, gamma):\n",
    "    \"\"\"\n",
    "    Computes new policy as argmax of state values\n",
    "    :param vpi: a dict {state : V^pi(state) for all states}\n",
    "    :returns: a dict {state : optimal action for all states}\n",
    "    \"\"\"\n",
    "    new_policy = {state: get_optimal_action(mdp, vpi, state, gamma) if len(mdp.get_possible_actions(s)) > 0 else '' \n",
    "                  for state in mdp.get_all_states()}\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): '', (0, 1): '', (0, 2): '', (0, 3): '', (1, 0): '', (1, 1): '', (1, 2): '', (1, 3): '', (2, 0): '', (2, 1): '', (2, 2): '', (2, 3): '', (3, 0): '', (3, 1): '', (3, 2): '', (3, 3): ''}\n"
     ]
    }
   ],
   "source": [
    "new_policy = compute_new_policy(mdp, new_vpi, gamma)\n",
    "\n",
    "print(new_policy)\n",
    "\n",
    "assert type(\n",
    "    new_policy) is dict, \"compute_new_policy must return a dict {state : optimal action for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Main loop__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(mdp, policy=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" \n",
    "    Run the policy iteration loop for num_iter iterations or till difference between V(s) is below min_difference.\n",
    "    If policy is not given, initialize it at random.\n",
    "    \"\"\"\n",
    "    if policy is None:\n",
    "        policy = {s: np.random.choice(mdp.get_possible_actions(s)) if len(mdp.get_possible_actions(s)) > 0 else '' \n",
    "                  for s in mdp.get_all_states() \n",
    "                  }\n",
    "    previous_vpi = None\n",
    "    for iteration in range(num_iter):\n",
    "        print(\"Iteration #{0}\".format(iteration))\n",
    "        vpi = compute_vpi(mdp, policy, gamma)\n",
    "        biggest_difference = None\n",
    "        if (not (previous_vpi is None)):\n",
    "            for state in mdp.get_all_states():\n",
    "                if (biggest_difference is None) or abs(vpi[state] - previous_vpi[state]) > biggest_difference:\n",
    "                    biggest_difference = abs(vpi[state] - previous_vpi[state])\n",
    "            if biggest_difference < min_difference:\n",
    "                break\n",
    "            print(\"Iteration #{0}, max difference = {1}\".format(iteration, biggest_difference))\n",
    "        policy = compute_new_policy(mdp, vpi, gamma)\n",
    "        previous_vpi = vpi\n",
    "        \n",
    "    return state_values, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your PI Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_value_and_policy_iteration(mdp):\n",
    "    gamma = 0.95\n",
    "    min_difference = 1e-3\n",
    "\n",
    "    print(\"Run value iteration.\")\n",
    "    vi_state_values = value_iteration(mdp, gamma=gamma, min_difference=min_difference)\n",
    "\n",
    "    print(\"Run policy iteration.\")\n",
    "    pi_state_values, resulted_policy = policy_iteration(mdp, gamma=gamma, min_difference=min_difference)\n",
    "\n",
    "    for state in mdp.get_all_states():\n",
    "        print(\"State {0}\".format(state))\n",
    "        print(\"Value iteration value: {0}\".format(vi_state_values[state]))\n",
    "        print(\"Policy iteration value: {0}\".format(pi_state_values[state]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run value iteration.\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.95000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.90250   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.85737   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.81451   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.77378   |   V(start): 0.774 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.774 \n",
      "Run policy iteration.\n",
      "Iteration #0\n",
      "Iteration #1\n",
      "State (0, 0)\n",
      "Value iteration value: 0.7737809374999999\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-3056c20872e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_value_and_policy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-e813138e2780>\u001b[0m in \u001b[0;36mcompare_value_and_policy_iteration\u001b[1;34m(mdp)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"State {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Value iteration value: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvi_state_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Policy iteration value: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi_state_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0)"
     ]
    }
   ],
   "source": [
    "compare_value_and_policy_iteration(mdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили 136 итераций у value_iteration против 2 у policy_iteration.\n",
    "\n",
    "Теперь черёд FrozenLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0):4\n",
      "(0, 1):4\n",
      "(0, 2):4\n",
      "(0, 3):4\n",
      "(1, 0):4\n",
      "(1, 1):0\n",
      "(1, 2):4\n",
      "(1, 3):0\n",
      "(2, 0):4\n",
      "(2, 1):4\n",
      "(2, 2):4\n",
      "(2, 3):0\n",
      "(3, 0):0\n",
      "(3, 1):4\n",
      "(3, 2):4\n",
      "(3, 3):0\n"
     ]
    }
   ],
   "source": [
    "for s in mdp.get_all_states():\n",
    "    print('{0}:{1}'.format(s, len(mdp.get_possible_actions(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run value iteration.\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.95000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.90250   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.85737   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.81451   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.77378   |   V(start): 0.774 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.774 \n",
      "Run policy iteration.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3056c20872e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_value_and_policy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-e813138e2780>\u001b[0m in \u001b[0;36mcompare_value_and_policy_iteration\u001b[1;34m(mdp)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Run policy iteration.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpi_state_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresulted_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_difference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_difference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-ab34f760a174>\u001b[0m in \u001b[0;36mpolicy_iteration\u001b[1;34m(mdp, policy, gamma, num_iter, min_difference)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprevious_vpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-ab34f760a174>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprevious_vpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "compare_value_and_policy_iteration(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
